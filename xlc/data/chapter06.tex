\section{实验论证}

\subsection{数据集}
本实验采用了MovieLens\footnote{\url{http://grouplens.org/datasets/movielens/}}100k的数据集.并随机分割了数据集的80\%作为训练数据, 其余20\%作为测试数据。

\textbf{MovieLens}包含了943个用户对于1682个电影的100,000个评分数据。每个用户至少对20个电影评过分。在实验中, 用户的职业信息(occupational description)被用作用户的内容信息(content information), 电影标题中的关键词被用作电影的内容信息。与\cite{gunawardana2009unified}中的处理过程相同, 我们并不直接使用用户的等级评分数据, 而将其转化为隐式反馈数据(对电影评过分为positive, 未评过分为negative)来使用, 以此推测是否用户是否会有对电影进行评分的行为。因此, 对于一个特定的用户而言, 我们的任务就是为其预测的一个有着潜在评分可能电影的排序列表。

如图\ref{gra6}所示, MovieLens中的用户所评分过电影数目显然呈长尾分布, 有422个近一半的用户所评分过的电影个数在区间$[20, 56]$中。
\begin{figure}[htbp]
	% caption放上面就会显示在图的上方，出现在下面就是出现在图的下方
	
	\begin{center}
		\includegraphics[width=5in]{longtail}
		\caption{用户对电影评分个数区间的长尾分布}
		\label{gra6}
	\end{center}
\end{figure}

\subsection{评测标准}

\textbf{MAP:} 先看AP(Average Precision), AP即为平均准确率。对于AP可以用这种方式理解: 假使当我们使用google搜索某个关键词，返回了10个结果。当然最好的情况是这10个结果都是我们想要的相关信息。但是假如只有部分是相关的，比如5个，那么这5个结果如果被显示的比较靠前也是一个相对不错的结果。但是如果这个5个相关信息从第6个返回结果才开始出现，那么这种情况便是比较差的。这便是AP所反映的指标，与recall的概念有些类似，不过是“顺序敏感的recall”。

对于$u$的平均准确率定义为：
\begin{equation*}
AP_u = \frac{1}{|\mathcal{I}_u^{te}|}\sum_{i \in \mathcal{I}_u^{te}}\frac{\sum_{j \in \mathcal{I}_u^{te}}\delta \left(p_{uj} \prec p_{ui}\right) + 1}{p_{ui}}
\end{equation*}
在这里$p_{ui}$表示推荐列表中物品$i$的排序位置。$p_{uj} \prec p_{ui}$表示在对用户$u$的排序列表中物品$j$的排序位置在物品$i$的前面。

对于MAP(Mean Average Precision)就很容易知道即为所有用户的AP的均值而已。那么则有：
\begin{equation*}
MAP = \frac{\sum_{u \in \mathcal{U}^{te}}AP_u}{|\mathcal{U}^{te}|}
\end{equation*}


\textbf{NDCG:}
先从CG(Cummulative Gain)说起,  CG即将每个推荐结果相关性的分值累加后作为整个推荐列表的得分。
\begin{equation*}
CG_p = \sum_{i=1}^p rel_i
\end{equation*}
在$rel_i$表示处于位置$i$的推荐结果的相关性，$p$表示所要考察的推荐列表的大小

CG的一个缺点是没有考虑结果处于不同位置对结果的影响，例如我们总是希望相关性高的结果应排在前面，相关性低的结果排在靠前的位置会严重影响用户体验， 所以在CG的基础上引入位置影响因素，即DCG(Discounted Cummulative Gain):
\begin{equation*}
DCG_p = \sum_{i=1}^p \frac{2^{rel_i}-1}{\log_2 \left(i+1\right)}
\end{equation*}

DCG仍然有其局限之处，即不同的推荐列表之间，很难进行横向的评估。而我们评估一个推荐系统，不可能仅使用一个用户的推荐列表及相应结果进行评估， 而是对整个测试集中的用户及其推荐列表结果进行评估。 那么不同用户的推荐列表的评估分数就需要进行归一化，也即NDCG(Normalized Discounted Cummulative Gain)。

IDCG(Ideal DCG)为推荐系统某一用户返回的最好结果， 即假设返回结果按照相关性排序， 最相关的结果放在最前面， 此序列的DCG为IDCG。因此DCG的值介于 $(0,IDCG]$，故NDCG的值介于$(0,1]$.

对于用户$u$的NDCG@k定义为：
\begin{equation*}
NDCG_u@k = \frac{DCG_u@k}{IDCG_u}
\end{equation*}

那么，则有：
\begin{equation*}
NDCG@k = \frac{\sum_{u\in \mathcal{U}^{te}}NDCG_u@k}{|\mathcal{U}^{te}|}
\end{equation*}

在具体操作中， 可以事先确定推荐目标和推荐结果的相关系分级， 例如可以使用 0，1分别表示相关或不相关，比如此处我们用$ref_i = \delta \left( i \in \mathcal{I}_u^{te}\right)$ , 在这里如果$x$为true, 则$\delta\left(x\right) = 1$，否则$\delta \left(x\right) = 0$. 或是这是0~5分别表示严重不相关到非常相关, 也即相当于确定了$rel$值的范围。之后对于每一个推荐目标的返回结果给定$rel$值，然后使用DCG的计算公式计计算出返回结果的DCG值。使用根据排序后的$rel$值序列计算IDCG值， 即可计算NDCG.

\subsection{实验过程与分析}
我们对BPR-MF与CA-BPR分别就MAP与NDCG评测指标进行了比较。BPR-MF\cite{rendle2009bpr}应用了矩阵分解的BPR算法框架，同时采用均匀采样策略选取训练采样。CA-BPR\cite{DBLP:conf/webi/GuoWWT15}在利用了隐式反馈数据的基础上同时融入了内容信息，并采取非均匀的适应性采样策略。

表\ref{tab:characteristic}显示了实验方法的不同之处。
\begin{table}[htbp]
	\caption{BPR-MF与CA-BPR方法特征比较}
	\renewcommand\arraystretch{1.3}%改变行高
	\label{tab:characteristic}
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Method   &   Content & Sampling   \\
			\hline
			BPR-MF   &   no      & uniform    \\
			CA-BPR   &   yes     & non-uniform\\
			\hline
			
		\end{tabular}
	\end{center}
\end{table}

表\ref{tab:mapandndcg}显示了BPR-MF与CA-BPR的MAP与NDCG实验结果。
\begin{table}[htbp]
	\caption{不同维度k下算法MAP与NDCG实验结果}
	\label{tab:mapandndcg}
	\begin{center}
		\begin{tabular}{|c | c |c |c|c|c|}
			\hline
			BPR-MF  &   k=10 &   k=20 &    k=30&    k=40&    k=50\\
			\hline
			MAP      &  0.0879&  0.0877&  0.1043&  0.0888&  0.1074\\
			\hline
			NDCG@3   &  0.3051&  0.3545&  0.3398&  0.2491&  0.3790\\
			NDCG@5   &  0.3616&  0.4296&  0.3708&  0.2984&  0.4153\\
			NDCG@10  &  0.4120&  0.4632&  0.4010&  0.3163&  0.4458\\
			NDCG@20  &  0.4121&  0.4575&  0.4164&  0.3415&  0.4323\\
			\hline
		\end{tabular}
		
	\end{center}
\end{table}
\begin{table}[htbp]
		\vspace{-1em}
		\begin{center}
			
		\begin{tabular}{|c | c |c |c|c|c|}
			\hline
			CA-BPR  &     k=10&   k=20 &    k=30&  k=40 &   k=50  \\
			\hline
			MAP     &   0.1074&  0.1072&  0.1274&  0.1016&  0.1229\\
			\hline
			NDCG@3  &   0.3790&  0.4336&  0.4152&  0.3044&  0.4631\\
			NDCG@5  &   0.4153&  0.4752&  0.4531&  0.3646&  0.5074\\
			NDCG@10 &   0.4458&  0.5101&  0.4900&  0.3865&  0.5447\\
			NDCG@20 &   0.4323&  0.4946&  0.5088&  0.4173&  0.5282\\
			\hline
		\end{tabular}
	\end{center}
\end{table}

图\ref{fig:map}显示了BPR-MF与CA-BPR在不同维度下的MAP结果对比。显然，融合了内容信息同时采用适应性采样策略的CA-BPR推荐效果比BPR-MF要好，由此说明内容信息及适应性采样策略的确是有效的。
\begin{figure}[htbp]
	\begin{center}
	\includegraphics[width=4in]{mapbar}
\end{center}
\caption{不同维度算法MAP结果对比}
\label{fig:map}
\end{figure}
